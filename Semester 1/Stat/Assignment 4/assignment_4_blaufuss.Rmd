---
title: "assignment_4_blaufuss"
author: "Dennis Blaufuss"
date: "12/01/2021"
output:
  html_document:
    df_print: paged
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rethinking)
library(tidyverse)

# Note: I knit to html and then save the html file to pdf to receive the submitted result. Thus this Markdown isn't optimized for knitting to pdf. I choose this workaround since I encountered a lot of weird issues with knitting the pdf in the first place (I guess M1 related as usual :D)
```

##### 1. The following plot of the posterior predictions of the Chimpanzee experiment is the bottom panel of Figure 11.4 on page 333.


![](/Users/dennisblaufuss/Desktop/SS_assignment_4.png)

##### Adapt the code in the book for plotting the observed data (Figure 11.4, top panel) to recreate this posterior predictions plot. Your answer must include the plot and your code.

```{r, results='hide'}
data(chimpanzees)
d <- chimpanzees
d$treatment <- 1 + d$prosoc_left + 2*d$condition

dat_list <- list(
    pulled_left = d$pulled_left,
    actor = d$actor,
    treatment = as.integer(d$treatment) )

m1 <- ulam(
    alist(
        pulled_left ~ dbinom(1, p ) ,
        logit(p) <- a[actor] + b[treatment] ,
        a[actor] ~ dnorm( 0 , 1.5 ),
        b[treatment] ~ dnorm( 0 , 0.5 )
    ),
    data=dat_list,
    chains=4,
    log_lik=TRUE )

# Code given in book:
pl <- by( d$pulled_left , list( d$actor , d$treatment ) , mean )

plot( NULL , xlim=c(1,28) , ylim=c(0,1) , xlab="" ,
    ylab="proportion left lever" , xaxt="n" , yaxt="n" )
axis( 2 , at=c(0,0.5,1) , labels=c(0,0.5,1) )
abline( h=0.5 , lty=2 )
for ( j in 1:7 ) abline( v=(j-1)*4+4.5 , lwd=0.5 )
for ( j in 1:7 ) text( (j-1)*4+2.5 , 1.1 , concat("actor ",j) , xpd=TRUE )
for ( j in (1:7)[-2] ) {
    lines( (j-1)*4+c(1,3) , pl[j,c(1,3)] , lwd=2 , col=rangi2 )
    lines( (j-1)*4+c(2,4) , pl[j,c(2,4)] , lwd=2 , col=rangi2 )
}
points( 1:28 , t(pl) , pch=16 , col="white" , cex=1.7 )
points( 1:28 , t(pl) , pch=c(1,1,16,16) , col=rangi2 , lwd=2 )
yoff <- 0.01
text( 1 , pl[1,1]-yoff , "R/N" , pos=1 , cex=0.8 )
text( 2 , pl[1,2]+yoff , "L/N" , pos=3 , cex=0.8 )
text( 3 , pl[1,3]-yoff , "R/P" , pos=1 , cex=0.8 )
text( 4 , pl[1,4]+yoff , "L/P" , pos=3 , cex=0.8 )
mtext( "observed proportions\n" )
```

###### Answer:

```{r}
dat_list2 <- list( actor=rep(1:7,each=4) , treatment=rep(1:4,times=7))
p_post <- link( m1 , data=dat_list2 )
p_mu <- apply( p_post , 2 , mean )
mu.PI <- apply( p_post , 2 , PI , prob=0.89 )
plot( NULL , xlim=c(1,28) , ylim=c(0,1) , xlab="" ,
ylab="proportion left lever" , xaxt="n" , yaxt="n" )
axis( 2 , at=c(0,0.5,1) , labels=c(0,0.5,1) )
abline( h=0.5 , lty=2 )
for ( j in 1:7 ) abline( v=(j-1)*4+4.5 , lwd=0.5 )
for ( j in 1:7 ) text( (j-1)*4+2.5 , 1.1 , concat("actor ",j) , xpd=TRUE ) 
for ( j in (1:7) ) {
    lines( (j-1)*4+c(1,3) , p_mu[4*(j-1)+c(1,3)] , lwd=2 , col=rangi2 )
    lines( (j-1)*4+c(2,4) , p_mu[4*(j-1)+c(2,4)] , lwd=2 , col=rangi2 )
}
for ( j in 1:28 ) lines( rep(j,2) , mu.PI[,j] , col=rangi2 ) 
points( 1:28 , t(p_mu) , pch=16 , col="white" , cex=1.7 ) 
points( 1:28 , t(p_mu) , pch=c(1,1,16,16) , col=rangi2 , lwd=2 ) 
yoff <- 0.01
mtext( "posterior predictions\n" )
```

***

##### 2. The Wines2012 data set includes expert scores given by expert American and French judges.

```{r}
data(Wines2012)
d <- Wines2012
precis(d)
```

##### You should standardize and create IDs to distinguish between American and French judges and American and French wines:

```{r}
# standardize scores and create IDs for
# American/French judges and wines
dat_list <- list(
 S = standardize(d$score),
 jid = as.integer(d$judge),
 wid = as.integer(d$wine)
 )
```

##### Your goal is to model the score, the subjective rating assigned by each judge to each wine.
##### For this first model, you should only consider variation among judges and wines.

##### (a) Construct index variables for judge and wine and using these index variables to construct a linear regression model. You should end up with 9 judge parameters and 20 wine parameters.
##### (b) Justify the priors you use.
##### (c) Use ulam instead of quap to build this model.
##### (d) Check your chains for convergence.
##### Is there variation among individual judges and individual wines? Are there patterns you can notice just by plotting the differences? Which judges have the lowest and highest ratings? Which wines are rated worst and which best on average?

```{r, results='hide'}
m2 <- ulam(
  alist(
    S ~ dnorm(mu, sigma),
    mu <- a[jid] + b[wid], 
    a[jid] ~ dnorm(0, 0.5), 
    b[wid] ~ dnorm(0, 0.5), 
    sigma ~dexp(1)
  ), 
  data=dat_list, 
  chains=4, 
  cores=4)

precis(m2, 2)
```

Note: I have disabled messages on this code block since with knitting it outputs an error but still the model works etc. As discussed in class briefly I guess this is due to M1. But since the model works and takes normal time to be computed I'm sure there is no issue (when running the code normally in RStudio everything works fine).

```{r}
traceplot(m2)
```

```{r}
plot(precis(m2, 2))
```

###### Answer:
(a) We indexed both wines and judges within in the standardizing code snippet: judges -> jid & wines -> wid. Using the tow ID's the model calculates us the asked for 9 and 20 parameters for judges and wines.

(b) Without the standardization (of the outcome) this step would be very (!) critical. Due to the standardization we may use the well known N(0, 0.5) for each and every prior. This somewhat leads to room for improvement / fine tuning but should be fine for now.

(c) See Code above and note the Note :D.

(d) The checking consists of several steps as discussed in class/lab: Firstly, having a look at the Rhat of prices function. (Recall that Rhat estimates the convergence between Markov chains and the target distribution.) With all Rhats being equal to 1 this is a good sign (Recall here again that this is only a sign and no proof at all.). Secondly, we will have a look at our n_eff's these are mostly above our sample size 2000 wich is a good sign (again: and only sign) as well. Lastly, we will look at the trace plots. They look like we called them in class like hairy caterpillars (weird naming but I see the resemblance). So all good looking here as well. Thus we can state here that we don't have any hints toward a problem.

While looking at the precis plot we can answer the question stated above: Firstly, let's focus on the a's, meaning the judges: We can note that Judge 8 is the harshest whilst judge 5 seems to love wine and general a lot and thus gives the best ratings. Furthermore, we see that there is a good distribution of the harshness over the span of all judges. Now, let's have a look at the b's and thus wines: Here we can see that the differences between all the wines aren't that big (in comparison to the judges). Still we can note that Wine 4 is slightly the best and wine 18 appears to be pretty bad (better said best/badly rated to be exact here).

***

##### 3. Now consider three features of the wines and judges:
* ##### flight: whether the wine is red or white.
* ##### wine.amer: Indicator variable for American wines
* ##### judge.amer: Indicator variable for American judges

##### Use indicator variables to model the influence of these features on the scores.
##### Here is a line of R code to convert the flight values (strings) to integer values of an indicator:

```{r}
# indicator for red wine
R = ifelse(d$flight =="red", 1L, 0L)
```

__Tip:__ _Note that 1L and 0L are integers, whereas 1 and 0 are real (actually, floating point) numbers. Indicator and index values should be integers._

##### Specifically,
##### (a) Omit the individual judge and wine index variables from Problem 2.
##### (b) Do not include interaction effects.
##### (c) Use ulam, justify your priors, and check your chains.
##### What do you conclude about the differences among the wines and judges? Compare your results to the results from Problem 2.

```{r, results='hide'}
dat_list2 <- list(
    S = standardize(d$score),
    W = d$wine.amer,
    J = d$judge.amer,
    R = ifelse(d$flight == "red", 1L, 0L))

m3 <- ulam(
  alist(
    S ~ dnorm(mu, sigma),
    mu <- a + bW*W + bJ*J + bR*R, 
    a ~ dnorm(0, 0.2), 
    bW~ dnorm(0, 0.5),
    bJ~ dnorm(0, 0.5),
    bR~ dnorm(0, 0.5),
    sigma ~ dexp(1)
    ), 
  data=dat_list2, 
  chains=4 , 
  cores=4)

precis(m3)
```

Same note as for previous model applies.

```{r}
traceplot(m3)
```

```{r}
plot(precis(m3, 2))
```

###### Answer:

(a) See chosen data in dat_list2 (Note: all three variables being indicator ones and standardizing the outcome again).

(b) See model: no interaction effects included (just basic adding up (with a weight as factor) of the three variables).

(c) See model for usage of ulam. Due to the mentioned standardization we can use our common priors for th weights again: N(0, 0.5). For a the standardization allows us the usage of the narrower N(0, 0.2) as prior. Some note applies for fine tuning as in problem 2. Checking wise all three checks used above look fine here as well. Just look at those cute caterpillars :D.

To answer the question above refer to the precis function output:

* The flight of the wine (meaning it being red or white) does not seem to have any impact on the rating on average (bR is around zero).

* The not American judges (thus french ones) seem to be the harsher ones (bJ above zero).

* The American wines seem to perform worse than the not American wines on average (bW below zero).

Since we take two different point of views in the two problems a direct comparison is difficult. I think whats worth mentioning here is: In problem two we saw that the judges are more different from each other than the wines. We somewhat see that as the origin of the judges has an impact on the rating while the flight doesn't. We still have to note that the origin of the wine still has an impact on the rating but slightly smaller one than for the judges. Obviously there are other impacts on the harshness of judges or rating of wine but those two observations give a small view on that.
